{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import count\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statistics\n",
    "from matplotlib import pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "sentimentAnalyser = SentimentIntensityAnalyzer()\n",
    "\n",
    "# DO: twarc2 timeline USER tweets.jsonl \n",
    "# NEXT DO: twarc2 csv tweets.jsonl tweets.csv\n",
    "# now the users tweets are in a useable csv format\n",
    "# organizes user tweets into more readable columns\n",
    "set_df = pd.read_csv('tweets.csv')\n",
    "set_df.rename(columns={'created_at': 'date',\n",
    "                          'public_metrics.retweet_count': 'retweets', \n",
    "                          'author.username': 'username', \n",
    "                          'author.name': 'name',\n",
    "                          'author.verified': 'verified', \n",
    "                          'public_metrics.like_count': 'likes', \n",
    "                          'public_metrics.quote_count': 'quotes', \n",
    "                          'public_metrics.reply_count': 'replies',\n",
    "                           'author.description': 'user_bio'},\n",
    "                            inplace=True)\n",
    "set_df = set_df[['text']]\n",
    "#set_df = set_df[['date', 'username', 'text']]\n",
    "\n",
    "# List of text of all 3200 tweets from user\n",
    "Text_list = set_df['text'].tolist()\n",
    "\n",
    "#creates variables to be used in for loop\n",
    "count=0\n",
    "score=0\n",
    "set = []\n",
    "setcnt = []\n",
    "\n",
    "# Loop through list of sentences and assign Vader score\n",
    "for text in Text_list:\n",
    "    # Run VADER on each sentence\n",
    "    sentiment_scores = sentimentAnalyser.polarity_scores(text)\n",
    "    sc = sentiment_scores['compound']\n",
    "    #below can be uncommented if rounding is desired which can make histogram use easier\n",
    "    #sc = int((sc * 100) + 0.5) / 100.0\n",
    "    score += sc\n",
    "    count += 1\n",
    "    setcnt.append(count)\n",
    "    set.append(sc)\n",
    "\n",
    "#sorts list and prints the list then makes histogram\n",
    "#histogram does not need to be 50 bins, but i think at 50 bins it looks the best\n",
    "set.sort()\n",
    "print(set)\n",
    "plt.hist(set, 50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import tweepy\n",
    "import csv\n",
    "client = tweepy.Client('AAAAAAAAAAAAAAAAAAAAACK8dgEAAAAAKPrElap%2BuwrTifb2d3t%2FMvab0jc%3DWXhCbe542Qxo3ci6Itl2OUMmj0zuVkzDCgTA6c2C3QlfpVz3hF')\n",
    "\n",
    "#writes recent tweets to a csv file from user id\n",
    "def write(id):\n",
    "    tw_df = str(client.get_users_tweets(id, end_time=None, exclude=None, expansions=None, max_results=100, media_fields=None, pagination_token=None, place_fields=None, poll_fields=None, since_id=None, start_time=None, tweet_fields=None, until_id=None, user_fields=None, user_auth=False))\n",
    "    f = open('user_tweets.csv', \"a\", encoding=\"utf-8\")\n",
    "    #f = csv.writer('user_tweets.csv', \"a\", encoding=\"utf-8\")\n",
    "    f.write(split + tw_df + '\\n')\n",
    "    f.close()\n",
    "\n",
    "#converts users screen name into its numerical user id\n",
    "def return_twitterid(screen_name):\n",
    "    twitterid = client.get_user(username=screen_name)\n",
    "    #print(type(twitterid)) \n",
    "    return(f\"{twitterid.data.id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#makes txt file more readeable\n",
    "text_file = open(\"usernames.txt\", \"r\")\n",
    "data = text_file.read()\n",
    "text_file.close()\n",
    "\n",
    "#writes tweets from all users in 'usernames.txt to csv file\n",
    "splits = data.split()\n",
    "for split in splits:\n",
    "    #print(split)\n",
    "    mid = return_twitterid(str(split))\n",
    "    #print(mid)\n",
    "    write(mid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"user_tweets.csv\", \"w\")\n",
    "f.truncate()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/colbyeagan/Twitter/twitt.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 24>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/colbyeagan/Twitter/twitt.ipynb#ch0000003?line=20'>21</a>\u001b[0m     \u001b[39mlist\u001b[39m\u001b[39m.\u001b[39mappend(\u001b[39m\"\u001b[39m\u001b[39mDennis Hong\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/colbyeagan/Twitter/twitt.ipynb#ch0000003?line=22'>23</a>\u001b[0m dfx \u001b[39m=\u001b[39m dfx[[\u001b[39m'\u001b[39m\u001b[39musername\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mname\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mpublic_metrics\u001b[39m\u001b[39m'\u001b[39m]]\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/colbyeagan/Twitter/twitt.ipynb#ch0000003?line=23'>24</a>\u001b[0m dfx[\u001b[39m'\u001b[39m\u001b[39mfollower\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(\u001b[39mlist\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/colbyeagan/Twitter/twitt.ipynb#ch0000003?line=24'>25</a>\u001b[0m dfx\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "data = []\n",
    "\n",
    "for line in open('user.json', 'r'):\n",
    "\n",
    "                data.append(json.loads(line))\n",
    "\n",
    "x = []\n",
    "\n",
    "for part in data:\n",
    "\n",
    "                part = part['data']\n",
    "\n",
    "                x+=part\n",
    "\n",
    "dfx = pd.DataFrame(x)\n",
    "list = []\n",
    "for x in range(len(dfx)):\n",
    "    list.append(\"Dennis Hong\")\n",
    "\n",
    "dfx = dfx[['username', 'name', 'public_metrics']]\n",
    "dfx['follower'] = np.array(list)\n",
    "dfx"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
